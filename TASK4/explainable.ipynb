{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,  export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187534 entries, 0 to 187533\n",
      "Data columns (total 31 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   date                       187534 non-null  datetime64[ns]\n",
      " 1   state                      187534 non-null  object        \n",
      " 2   city_or_county             187534 non-null  object        \n",
      " 3   latitude                   187534 non-null  float64       \n",
      " 4   longitude                  187534 non-null  float64       \n",
      " 5   congressional_district     187534 non-null  int64         \n",
      " 6   avg_age_participants       187534 non-null  float64       \n",
      " 7   n_participants_child       187534 non-null  int64         \n",
      " 8   n_participants_teen        187534 non-null  int64         \n",
      " 9   n_females                  187534 non-null  float64       \n",
      " 10  n_killed                   187534 non-null  float64       \n",
      " 11  n_injured                  187534 non-null  float64       \n",
      " 12  n_arrested                 187534 non-null  float64       \n",
      " 13  n_unharmed                 187534 non-null  float64       \n",
      " 14  n_participants             187534 non-null  float64       \n",
      " 15  incident_characteristics1  187534 non-null  object        \n",
      " 16  povertyPercentage          187534 non-null  float64       \n",
      " 17  party                      187534 non-null  object        \n",
      " 18  candidatevotes             187534 non-null  int64         \n",
      " 19  totalvotes                 187534 non-null  int64         \n",
      " 20  incident_gravity           187534 non-null  float64       \n",
      " 21  females_rate               187534 non-null  float64       \n",
      " 22  minor_rate                 187534 non-null  float64       \n",
      " 23  arrested_rate              187534 non-null  float64       \n",
      " 24  survival_rate              187534 non-null  float64       \n",
      " 25  winning_party_percentage   187534 non-null  float64       \n",
      " 26  killed_rate                187534 non-null  float64       \n",
      " 27  injured_rate               187534 non-null  float64       \n",
      " 28  killed_disp_per_district   187534 non-null  float64       \n",
      " 29  injured_disp_per_district  187534 non-null  float64       \n",
      " 30  part_disp_per_district     187534 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(21), int64(5), object(4)\n",
      "memory usage: 44.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Task1/df_after_dp.csv', parse_dates=['date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187534 entries, 0 to 187533\n",
      "Data columns (total 32 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   date                       187534 non-null  datetime64[ns]\n",
      " 1   state                      187534 non-null  object        \n",
      " 2   city_or_county             187534 non-null  object        \n",
      " 3   latitude                   187534 non-null  float64       \n",
      " 4   longitude                  187534 non-null  float64       \n",
      " 5   congressional_district     187534 non-null  int64         \n",
      " 6   avg_age_participants       187534 non-null  float64       \n",
      " 7   n_participants_child       187534 non-null  int64         \n",
      " 8   n_participants_teen        187534 non-null  int64         \n",
      " 9   n_females                  187534 non-null  float64       \n",
      " 10  n_killed                   187534 non-null  float64       \n",
      " 11  n_injured                  187534 non-null  float64       \n",
      " 12  n_arrested                 187534 non-null  float64       \n",
      " 13  n_unharmed                 187534 non-null  float64       \n",
      " 14  n_participants             187534 non-null  float64       \n",
      " 15  incident_characteristics1  187534 non-null  object        \n",
      " 16  povertyPercentage          187534 non-null  float64       \n",
      " 17  party                      187534 non-null  object        \n",
      " 18  candidatevotes             187534 non-null  int64         \n",
      " 19  totalvotes                 187534 non-null  int64         \n",
      " 20  incident_gravity           187534 non-null  float64       \n",
      " 21  females_rate               187534 non-null  float64       \n",
      " 22  minor_rate                 187534 non-null  float64       \n",
      " 23  arrested_rate              187534 non-null  float64       \n",
      " 24  survival_rate              187534 non-null  float64       \n",
      " 25  winning_party_percentage   187534 non-null  float64       \n",
      " 26  killed_rate                187534 non-null  float64       \n",
      " 27  injured_rate               187534 non-null  float64       \n",
      " 28  killed_disp_per_district   187534 non-null  float64       \n",
      " 29  injured_disp_per_district  187534 non-null  float64       \n",
      " 30  part_disp_per_district     187534 non-null  float64       \n",
      " 31  isKilled                   187534 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(21), int64(6), object(4)\n",
      "memory usage: 45.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df['isKilled'] = np.where(df['n_killed'] > 0, 1, 0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_data(dataset, variables):\n",
    "    for variable in variables:\n",
    "        #get the unique variable's values\n",
    "        var = sorted(dataset[variable].unique())\n",
    "        \n",
    "        #generate a mapping from the variable's values to the number representation  \n",
    "        mapping = dict(zip(var, range(0, len(var) + 1)))\n",
    "\n",
    "        #add a new colum with the number representation of the variable\n",
    "        dataset[variable+'_num'] = dataset[variable].map(mapping).astype(int)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_discretize = ['date', 'state', 'city_or_county', 'party', 'incident_characteristics1']\n",
    "df = discretize_data(df, to_discretize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187534 entries, 0 to 187533\n",
      "Data columns (total 32 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   latitude                       187534 non-null  float64\n",
      " 1   longitude                      187534 non-null  float64\n",
      " 2   congressional_district         187534 non-null  int64  \n",
      " 3   avg_age_participants           187534 non-null  float64\n",
      " 4   n_participants_child           187534 non-null  int64  \n",
      " 5   n_participants_teen            187534 non-null  int64  \n",
      " 6   n_females                      187534 non-null  float64\n",
      " 7   n_killed                       187534 non-null  float64\n",
      " 8   n_injured                      187534 non-null  float64\n",
      " 9   n_arrested                     187534 non-null  float64\n",
      " 10  n_unharmed                     187534 non-null  float64\n",
      " 11  n_participants                 187534 non-null  float64\n",
      " 12  povertyPercentage              187534 non-null  float64\n",
      " 13  candidatevotes                 187534 non-null  int64  \n",
      " 14  totalvotes                     187534 non-null  int64  \n",
      " 15  incident_gravity               187534 non-null  float64\n",
      " 16  females_rate                   187534 non-null  float64\n",
      " 17  minor_rate                     187534 non-null  float64\n",
      " 18  arrested_rate                  187534 non-null  float64\n",
      " 19  survival_rate                  187534 non-null  float64\n",
      " 20  winning_party_percentage       187534 non-null  float64\n",
      " 21  killed_rate                    187534 non-null  float64\n",
      " 22  injured_rate                   187534 non-null  float64\n",
      " 23  killed_disp_per_district       187534 non-null  float64\n",
      " 24  injured_disp_per_district      187534 non-null  float64\n",
      " 25  part_disp_per_district         187534 non-null  float64\n",
      " 26  isKilled                       187534 non-null  int64  \n",
      " 27  date_num                       187534 non-null  int64  \n",
      " 28  state_num                      187534 non-null  int64  \n",
      " 29  city_or_county_num             187534 non-null  int64  \n",
      " 30  party_num                      187534 non-null  int64  \n",
      " 31  incident_characteristics1_num  187534 non-null  int64  \n",
      "dtypes: float64(21), int64(11)\n",
      "memory usage: 45.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=['date', 'state', 'city_or_county', 'party', 'incident_characteristics1'], axis=1,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = ['latitude', 'longitude', 'n_killed', 'candidatevotes', 'totalvotes', 'incident_gravity', 'females_rate',\n",
    "       'minor_rate', 'arrested_rate', 'survival_rate',  'killed_rate', 'injured_rate',\n",
    "       'killed_disp_per_district', 'injured_disp_per_district',\n",
    "       'part_disp_per_district', 'winning_party_percentage', 'n_injured','n_unharmed', \"incident_characteristics1_num\"]\n",
    "\n",
    "df.drop(columns=col_to_drop, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.pop('isKilled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trvl, X_test, y_trvl, y_test = train_test_split(df, label, test_size=0.30,random_state=10, stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_cv(results_hp_search, model_name):\n",
    "    index_best_model = results_hp_search.best_index_ \n",
    "    results_dict = results_hp_search.cv_results_\n",
    "    metrics_list=['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    if model_name == 'MLP':\n",
    "        metrics_list.append('mse')\n",
    "    print(f\"CV best configuration for {model_name}:\")\n",
    "    print(f\"best parameters {results_dict['params'][index_best_model]}\")\n",
    "    for i in metrics_list:        \n",
    "        if i == 'mse':\n",
    "            print(f'Mean {i} train set: {abs(results_dict[f\"mean_train_{i}\"][index_best_model])} +/- {results_dict[f\"std_train_{i}\"][index_best_model]}')\n",
    "            continue\n",
    "        print(f'Mean {i} train set: {results_dict[f\"mean_train_{i}\"][index_best_model]} +/- {results_dict[f\"std_train_{i}\"][index_best_model]}')\n",
    "    print(\"\\n\")\n",
    "    for i in metrics_list:\n",
    "        if i == 'mse':\n",
    "            print(f'Mean {i} train set: {abs(results_dict[f\"mean_test_{i}\"][index_best_model])} +/- {results_dict[f\"std_test_{i}\"][index_best_model]}')\n",
    "            continue\n",
    "        print(f'Mean {i} validation set: {results_dict[f\"mean_test_{i}\"][index_best_model]} +/- {results_dict[f\"std_test_{i}\"][index_best_model]}')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that prints the classification report\n",
    "def print_report_score(test_label, test_pred):\n",
    "    print(classification_report(test_label, \n",
    "                            test_pred, \n",
    "                            target_names=['NotKilled', 'isKilled']))\n",
    "\n",
    "# Function that prints the confusion matrix\n",
    "def print_confusion_matrix(test_label, pred_label, model):\n",
    "    cm = confusion_matrix(test_label, pred_label)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function extracting each grid from dictionary of grids\n",
    "def list_grids(grids_dict):\n",
    "    return [grids_dict[item] for item in grids_dict]\n",
    "\n",
    "# Function performing gridsearch cv according to sklearn\n",
    "def do_sklearn_GridSearchCV(model_name,model,param_grid,scoring,refit,cv,return_train_score,n_jobs,X_encoded,y):\n",
    "    hp_search = GridSearchCV(model,\n",
    "                                param_grid=param_grid,\n",
    "                                scoring=scoring,\n",
    "                                refit=refit,\n",
    "                                cv=cv,\n",
    "                                return_train_score=return_train_score,\n",
    "                                n_jobs=n_jobs,\n",
    "                                verbose=10\n",
    "                                ).fit(X_encoded, y)\n",
    "\n",
    "\n",
    "    results = pd.DataFrame(hp_search.cv_results_)\n",
    "    if not os.path.isdir(f\"cv_results/\"):\n",
    "        os.mkdir(f\"cv_results/\")\n",
    "\n",
    "    results.to_csv(f\"cv_results/{model_name}_cv_results.csv\")\n",
    "\n",
    "    return hp_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/81] START learning_rate=0.01, max_leaves=3, min_samples_leaf=1, n_estimators=100, random_state=10\n",
      "[CV 2/5; 1/81] START learning_rate=0.01, max_leaves=3, min_samples_leaf=1, n_estimators=100, random_state=10\n",
      "[CV 3/5; 1/81] START learning_rate=0.01, max_leaves=3, min_samples_leaf=1, n_estimators=100, random_state=10\n",
      "[CV 5/5; 1/81] START learning_rate=0.01, max_leaves=3, min_samples_leaf=1, n_estimators=100, random_state=10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'n_estimators' for estimator ExplainableBoostingClassifier(min_samples_leaf=1). Valid parameters are: ['early_stopping_rounds', 'early_stopping_tolerance', 'exclude', 'feature_names', 'feature_types', 'greediness', 'inner_bags', 'interactions', 'learning_rate', 'max_bins', 'max_interaction_bins', 'max_leaves', 'max_rounds', 'min_samples_leaf', 'n_jobs', 'objective', 'outer_bags', 'random_state', 'smoothing_rounds', 'validation_size'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/lau/Library/Python/3.11/lib/python/site-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"/Users/lau/Library/Python/3.11/lib/python/site-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lau/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lau/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lau/Library/Python/3.11/lib/python/site-packages/sklearn/utils/parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lau/Library/Python/3.11/lib/python/site-packages/sklearn/model_selection/_validation.py\", line 717, in _fit_and_score\n    estimator = estimator.set_params(**clone(parameters, safe=False))\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/lau/Library/Python/3.11/lib/python/site-packages/sklearn/base.py\", line 230, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'n_estimators' for estimator ExplainableBoostingClassifier(min_samples_leaf=1). Valid parameters are: ['early_stopping_rounds', 'early_stopping_tolerance', 'exclude', 'feature_names', 'feature_types', 'greediness', 'inner_bags', 'interactions', 'learning_rate', 'max_bins', 'max_interaction_bins', 'max_leaves', 'max_rounds', 'min_samples_leaf', 'n_jobs', 'objective', 'outer_bags', 'random_state', 'smoothing_rounds', 'validation_size'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m ebm \u001b[38;5;241m=\u001b[39m ExplainableBoostingClassifier()\n\u001b[1;32m      5\u001b[0m ebm_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.05\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m]\n\u001b[1;32m     11\u001b[0m     }\n\u001b[0;32m---> 13\u001b[0m ebm_grid_search \u001b[38;5;241m=\u001b[39m \u001b[43mdo_sklearn_GridSearchCV\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mebm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mebm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mebm_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroc_auc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_trvl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trvl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m ebm\u001b[38;5;241m.\u001b[39mfit(X_trvl, y_trvl)\n\u001b[1;32m     17\u001b[0m ebm\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m, in \u001b[0;36mdo_sklearn_GridSearchCV\u001b[0;34m(model_name, model, param_grid, scoring, refit, cv, return_train_score, n_jobs, X_encoded, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_sklearn_GridSearchCV\u001b[39m(model_name,model,param_grid,scoring,refit,cv,return_train_score,n_jobs,X_encoded,y):\n\u001b[1;32m      7\u001b[0m     hp_search \u001b[38;5;241m=\u001b[39m \u001b[43mGridSearchCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mrefit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[0;32m---> 15\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(hp_search\u001b[38;5;241m.\u001b[39mcv_results_)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv_results/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[1;32m   1693\u001b[0m \n\u001b[1;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[1;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[0;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[0;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter 'n_estimators' for estimator ExplainableBoostingClassifier(min_samples_leaf=1). Valid parameters are: ['early_stopping_rounds', 'early_stopping_tolerance', 'exclude', 'feature_names', 'feature_types', 'greediness', 'inner_bags', 'interactions', 'learning_rate', 'max_bins', 'max_interaction_bins', 'max_leaves', 'max_rounds', 'min_samples_leaf', 'n_jobs', 'objective', 'outer_bags', 'random_state', 'smoothing_rounds', 'validation_size']."
     ]
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "ebm = ExplainableBoostingClassifier()\n",
    "\n",
    "ebm_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.05],\n",
    "    'random_state': [10],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_leaves': [3, 5, 7]\n",
    "    }\n",
    "\n",
    "ebm_grid_search = do_sklearn_GridSearchCV('ebm', ebm, ebm_grid, ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\"accuracy\", 5, True, 4, X_trvl, y_trvl)\n",
    "\n",
    "ebm.fit(X_trvl, y_trvl)\n",
    "\n",
    "ebm.predict(X_test)\n",
    "\n",
    "ebm.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/6438998736/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/6438998736/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret import show\n",
    "\n",
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/11096610960/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/11096610960/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebm_local = ebm.explain_local(X_test[:10], y_test[:10])\n",
    "show(ebm_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.830\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y_test, ebm.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC: {:.3f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, ebm.predict(X_test))\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/11096561104/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/11096561104/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.perf import ROC\n",
    "\n",
    "ebm_perf = ROC(ebm.predict_proba).explain_perf(X_test, y_test, name='EBM Adult')\n",
    "\n",
    "show(ebm_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aix360.metrics import faithfulness_metric, monotonicity_metric\n",
    "\n",
    "predicted_class = ebm.predict(X_test.values[0].reshape(1,-1))[0]\n",
    "\n",
    "le = exp.local_exp[predicted_class]\n",
    "\n",
    "m = exp.as_map()\n",
    "\n",
    "x = X_test.values[0]\n",
    "coefs = np.zeros(x.shape[0])\n",
    "\n",
    "for v in le:\n",
    "    coefs[v[0]] = v[1]\n",
    "\n",
    "\n",
    "base = np.zeros(x.shape[0])\n",
    "\n",
    "\n",
    "print(\"Faithfulness: \", faithfulness_metric(bb, x, coefs, base))\n",
    "print(\"Monotonity: \", monotonicity_metric(bb, x, coefs, base))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
