{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV,StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier,  export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187534 entries, 0 to 187533\n",
      "Data columns (total 31 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   date                       187534 non-null  datetime64[ns]\n",
      " 1   state                      187534 non-null  object        \n",
      " 2   city_or_county             187534 non-null  object        \n",
      " 3   latitude                   187534 non-null  float64       \n",
      " 4   longitude                  187534 non-null  float64       \n",
      " 5   congressional_district     187534 non-null  int64         \n",
      " 6   avg_age_participants       187534 non-null  float64       \n",
      " 7   n_participants_child       187534 non-null  int64         \n",
      " 8   n_participants_teen        187534 non-null  int64         \n",
      " 9   n_females                  187534 non-null  float64       \n",
      " 10  n_killed                   187534 non-null  float64       \n",
      " 11  n_injured                  187534 non-null  float64       \n",
      " 12  n_arrested                 187534 non-null  float64       \n",
      " 13  n_unharmed                 187534 non-null  float64       \n",
      " 14  n_participants             187534 non-null  float64       \n",
      " 15  incident_characteristics1  187534 non-null  object        \n",
      " 16  povertyPercentage          187534 non-null  float64       \n",
      " 17  party                      187534 non-null  object        \n",
      " 18  candidatevotes             187534 non-null  int64         \n",
      " 19  totalvotes                 187534 non-null  int64         \n",
      " 20  incident_gravity           187534 non-null  float64       \n",
      " 21  females_rate               187534 non-null  float64       \n",
      " 22  minor_rate                 187534 non-null  float64       \n",
      " 23  arrested_rate              187534 non-null  float64       \n",
      " 24  survival_rate              187534 non-null  float64       \n",
      " 25  winning_party_percentage   187534 non-null  float64       \n",
      " 26  killed_rate                187534 non-null  float64       \n",
      " 27  injured_rate               187534 non-null  float64       \n",
      " 28  killed_disp_per_district   187534 non-null  float64       \n",
      " 29  injured_disp_per_district  187534 non-null  float64       \n",
      " 30  part_disp_per_district     187534 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(21), int64(5), object(4)\n",
      "memory usage: 44.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Task1/df_after_dp.csv', parse_dates=['date'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187534 entries, 0 to 187533\n",
      "Data columns (total 32 columns):\n",
      " #   Column                     Non-Null Count   Dtype         \n",
      "---  ------                     --------------   -----         \n",
      " 0   date                       187534 non-null  datetime64[ns]\n",
      " 1   state                      187534 non-null  object        \n",
      " 2   city_or_county             187534 non-null  object        \n",
      " 3   latitude                   187534 non-null  float64       \n",
      " 4   longitude                  187534 non-null  float64       \n",
      " 5   congressional_district     187534 non-null  int64         \n",
      " 6   avg_age_participants       187534 non-null  float64       \n",
      " 7   n_participants_child       187534 non-null  int64         \n",
      " 8   n_participants_teen        187534 non-null  int64         \n",
      " 9   n_females                  187534 non-null  float64       \n",
      " 10  n_killed                   187534 non-null  float64       \n",
      " 11  n_injured                  187534 non-null  float64       \n",
      " 12  n_arrested                 187534 non-null  float64       \n",
      " 13  n_unharmed                 187534 non-null  float64       \n",
      " 14  n_participants             187534 non-null  float64       \n",
      " 15  incident_characteristics1  187534 non-null  object        \n",
      " 16  povertyPercentage          187534 non-null  float64       \n",
      " 17  party                      187534 non-null  object        \n",
      " 18  candidatevotes             187534 non-null  int64         \n",
      " 19  totalvotes                 187534 non-null  int64         \n",
      " 20  incident_gravity           187534 non-null  float64       \n",
      " 21  females_rate               187534 non-null  float64       \n",
      " 22  minor_rate                 187534 non-null  float64       \n",
      " 23  arrested_rate              187534 non-null  float64       \n",
      " 24  survival_rate              187534 non-null  float64       \n",
      " 25  winning_party_percentage   187534 non-null  float64       \n",
      " 26  killed_rate                187534 non-null  float64       \n",
      " 27  injured_rate               187534 non-null  float64       \n",
      " 28  killed_disp_per_district   187534 non-null  float64       \n",
      " 29  injured_disp_per_district  187534 non-null  float64       \n",
      " 30  part_disp_per_district     187534 non-null  float64       \n",
      " 31  isKilled                   187534 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(21), int64(6), object(4)\n",
      "memory usage: 45.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df['isKilled'] = np.where(df['n_killed'] > 0, 1, 0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_data(dataset, variables):\n",
    "    for variable in variables:\n",
    "        #get the unique variable's values\n",
    "        var = sorted(dataset[variable].unique())\n",
    "        \n",
    "        #generate a mapping from the variable's values to the number representation  \n",
    "        mapping = dict(zip(var, range(0, len(var) + 1)))\n",
    "\n",
    "        #add a new colum with the number representation of the variable\n",
    "        dataset[variable+'_num'] = dataset[variable].map(mapping).astype(int)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_discretize = ['date', 'state', 'city_or_county', 'party', 'incident_characteristics1']\n",
    "df = discretize_data(df, to_discretize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 187534 entries, 0 to 187533\n",
      "Data columns (total 32 columns):\n",
      " #   Column                         Non-Null Count   Dtype  \n",
      "---  ------                         --------------   -----  \n",
      " 0   latitude                       187534 non-null  float64\n",
      " 1   longitude                      187534 non-null  float64\n",
      " 2   congressional_district         187534 non-null  int64  \n",
      " 3   avg_age_participants           187534 non-null  float64\n",
      " 4   n_participants_child           187534 non-null  int64  \n",
      " 5   n_participants_teen            187534 non-null  int64  \n",
      " 6   n_females                      187534 non-null  float64\n",
      " 7   n_killed                       187534 non-null  float64\n",
      " 8   n_injured                      187534 non-null  float64\n",
      " 9   n_arrested                     187534 non-null  float64\n",
      " 10  n_unharmed                     187534 non-null  float64\n",
      " 11  n_participants                 187534 non-null  float64\n",
      " 12  povertyPercentage              187534 non-null  float64\n",
      " 13  candidatevotes                 187534 non-null  int64  \n",
      " 14  totalvotes                     187534 non-null  int64  \n",
      " 15  incident_gravity               187534 non-null  float64\n",
      " 16  females_rate                   187534 non-null  float64\n",
      " 17  minor_rate                     187534 non-null  float64\n",
      " 18  arrested_rate                  187534 non-null  float64\n",
      " 19  survival_rate                  187534 non-null  float64\n",
      " 20  winning_party_percentage       187534 non-null  float64\n",
      " 21  killed_rate                    187534 non-null  float64\n",
      " 22  injured_rate                   187534 non-null  float64\n",
      " 23  killed_disp_per_district       187534 non-null  float64\n",
      " 24  injured_disp_per_district      187534 non-null  float64\n",
      " 25  part_disp_per_district         187534 non-null  float64\n",
      " 26  isKilled                       187534 non-null  int64  \n",
      " 27  date_num                       187534 non-null  int64  \n",
      " 28  state_num                      187534 non-null  int64  \n",
      " 29  city_or_county_num             187534 non-null  int64  \n",
      " 30  party_num                      187534 non-null  int64  \n",
      " 31  incident_characteristics1_num  187534 non-null  int64  \n",
      "dtypes: float64(21), int64(11)\n",
      "memory usage: 45.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.drop(columns=['date', 'state', 'city_or_county', 'party', 'incident_characteristics1'], axis=1,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = ['latitude', 'longitude', 'n_killed', 'candidatevotes', 'totalvotes', 'incident_gravity', 'females_rate',\n",
    "       'minor_rate', 'arrested_rate', 'survival_rate',  'killed_rate', 'injured_rate',\n",
    "       'killed_disp_per_district', 'injured_disp_per_district',\n",
    "       'part_disp_per_district', 'winning_party_percentage', 'n_injured','n_unharmed', \"incident_characteristics1_num\"]\n",
    "\n",
    "df.drop(columns=col_to_drop, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.pop('isKilled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trvl, X_test, y_trvl, y_test = train_test_split(df, label, test_size=0.30,random_state=10, stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_cv(results_hp_search, model_name):\n",
    "    index_best_model = results_hp_search.best_index_ \n",
    "    results_dict = results_hp_search.cv_results_\n",
    "    metrics_list=['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    if model_name == 'MLP':\n",
    "        metrics_list.append('mse')\n",
    "    print(f\"CV best configuration for {model_name}:\")\n",
    "    print(f\"best parameters {results_dict['params'][index_best_model]}\")\n",
    "    for i in metrics_list:        \n",
    "        if i == 'mse':\n",
    "            print(f'Mean {i} train set: {abs(results_dict[f\"mean_train_{i}\"][index_best_model])} +/- {results_dict[f\"std_train_{i}\"][index_best_model]}')\n",
    "            continue\n",
    "        print(f'Mean {i} train set: {results_dict[f\"mean_train_{i}\"][index_best_model]} +/- {results_dict[f\"std_train_{i}\"][index_best_model]}')\n",
    "    print(\"\\n\")\n",
    "    for i in metrics_list:\n",
    "        if i == 'mse':\n",
    "            print(f'Mean {i} train set: {abs(results_dict[f\"mean_test_{i}\"][index_best_model])} +/- {results_dict[f\"std_test_{i}\"][index_best_model]}')\n",
    "            continue\n",
    "        print(f'Mean {i} validation set: {results_dict[f\"mean_test_{i}\"][index_best_model]} +/- {results_dict[f\"std_test_{i}\"][index_best_model]}')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that prints the classification report\n",
    "def print_report_score(test_label, test_pred):\n",
    "    print(classification_report(test_label, \n",
    "                            test_pred, \n",
    "                            target_names=['NotKilled', 'isKilled']))\n",
    "\n",
    "# Function that prints the confusion matrix\n",
    "def print_confusion_matrix(test_label, pred_label, model):\n",
    "    cm = confusion_matrix(test_label, pred_label)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function extracting each grid from dictionary of grids\n",
    "def list_grids(grids_dict):\n",
    "    return [grids_dict[item] for item in grids_dict]\n",
    "\n",
    "# Function performing gridsearch cv according to sklearn\n",
    "def do_sklearn_GridSearchCV(model_name,model,param_grid,scoring,refit,cv,return_train_score,n_jobs,X_encoded,y):\n",
    "    hp_search = GridSearchCV(model,\n",
    "                                param_grid=param_grid,\n",
    "                                scoring=scoring,\n",
    "                                refit=refit,\n",
    "                                cv=cv,\n",
    "                                return_train_score=return_train_score,\n",
    "                                n_jobs=n_jobs,\n",
    "                                verbose=10\n",
    "                                ).fit(X_encoded, y)\n",
    "\n",
    "\n",
    "    results = pd.DataFrame(hp_search.cv_results_)\n",
    "    if not os.path.isdir(f\"cv_results/\"):\n",
    "        os.mkdir(f\"cv_results/\")\n",
    "\n",
    "    results.to_csv(f\"cv_results/{model_name}_cv_results.csv\")\n",
    "\n",
    "    return hp_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m      5\u001b[0m ebm_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m],\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     15\u001b[0m ebm_grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(ebm, ebm_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mebm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trvl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trvl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m ebm\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     21\u001b[0m ebm\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/interpret/glassbox/_ebm/_ebm.py:895\u001b[0m, in \u001b[0;36mEBMModel.fit\u001b[0;34m(self, X, y, sample_weight, bags, init_score)\u001b[0m\n\u001b[1;32m    866\u001b[0m         init_score_local \u001b[38;5;241m=\u001b[39m init_score_local[bag \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m     parallel_args\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    869\u001b[0m         (\n\u001b[1;32m    870\u001b[0m             dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    892\u001b[0m         )\n\u001b[1;32m    893\u001b[0m     )\n\u001b[0;32m--> 895\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mprovider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[38;5;66;03m# let python reclaim the dataset memory via reference counting\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m parallel_args  \u001b[38;5;66;03m# parallel_args holds references to dataset, so must be deleted\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/interpret/provider/_compute.py:19\u001b[0m, in \u001b[0;36mJobLibProvider.parallel\u001b[0;34m(self, compute_fn, compute_args_iter)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel\u001b[39m(\u001b[38;5;28mself\u001b[39m, compute_fn, compute_args_iter):\n\u001b[0;32m---> 19\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompute_args_iter\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "ebm = ExplainableBoostingClassifier()\n",
    "\n",
    "ebm_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.05],\n",
    "    'random_state': [10],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_leaves': [3, 5, 7]\n",
    "    }\n",
    "\n",
    "ebm_grid_search = do_sklearn_GridSearchCV('ebm', ebm, ebm_grid, ['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\"accuracy\", 5, True, 4, X_trvl, y_trvl)\n",
    "\n",
    "ebm.fit(X_trvl, y_trvl)\n",
    "\n",
    "ebm.predict(X_test)\n",
    "\n",
    "ebm.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/6438998736/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/6438998736/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret import show\n",
    "\n",
    "ebm_global = ebm.explain_global()\n",
    "show(ebm_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/11096610960/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/11096610960/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebm_local = ebm.explain_local(X_test[:10], y_test[:10])\n",
    "show(ebm_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.830\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y_test, ebm.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC: {:.3f}\".format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.795\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, ebm.predict(X_test))\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- http://127.0.0.1:7001/11096561104/ -->\n",
       "<iframe src=\"http://127.0.0.1:7001/11096561104/\" width=100% height=800 frameBorder=\"0\"></iframe>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from interpret.perf import ROC\n",
    "\n",
    "ebm_perf = ROC(ebm.predict_proba).explain_perf(X_test, y_test, name='EBM Adult')\n",
    "\n",
    "show(ebm_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aix360.metrics import faithfulness_metric, monotonicity_metric\n",
    "\n",
    "predicted_class = ebm.predict(X_test.values[0].reshape(1,-1))[0]\n",
    "\n",
    "le = exp.local_exp[predicted_class]\n",
    "\n",
    "m = exp.as_map()\n",
    "\n",
    "x = X_test.values[0]\n",
    "coefs = np.zeros(x.shape[0])\n",
    "\n",
    "for v in le:\n",
    "    coefs[v[0]] = v[1]\n",
    "\n",
    "\n",
    "base = np.zeros(x.shape[0])\n",
    "\n",
    "\n",
    "print(\"Faithfulness: \", faithfulness_metric(bb, x, coefs, base))\n",
    "print(\"Monotonity: \", monotonicity_metric(bb, x, coefs, base))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
