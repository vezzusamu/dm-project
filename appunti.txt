ALASKA SCOMPARSA CON MERGE; IMPORTANTE RISOLVI HAMZA, ASAP!

DM progetto appunti
230337
Drop duplicates, dovrebbe droppare solo duplicati basati su tutte le colonne e non id

1) Controllare che le colonne non siano ambigue, per esempio numero partecipanti < numero teen

2) comando per controllare se un valore è nan ====> pd.isna(val)

3) 
df["state"] = df["state"].astype("string")
df["city_or_county"] = df["city_or_county"].astype("string")
df.info()

css = df[df['participant_gender1'] == 'Male, female'] per restiture la riga in cui la colonna assume quel valore.


4) Per tutti gli interi e float togliere i valori negativi.

5) controllare colonna avg_participant_age valori anormali (< 0 e > 120). Abbiamo notato che c'è una correlazione tra valori anormali e il fatto che & participant_age1 è nulla.
Metà dei record di avg_participant_age sono anormali se max_participant_age è nulla. (5827)

6) Per tutti gli interi e float, in cui non ha senso avere valori negativi, toglierli
Rimuovo le date superiori alla data in cui è stato assegnato il dataset.

7) Abbiamo rimosso outliers andando a trasformare avg_participant_age < 10 in 10 e > 60 in 60
8) Elimino duplicati aventi stessa data, lat e long

9) Assegnamo alle date null valori da una biased random distribution 
10) Sostituiamo le cordinate NaN con quelle di stesso stato e città, se nessuna corrispondenza esiste allora prendiamo solo lo stesso stato. 

Clustering:

1) try more metrics ("euclidean"...), try more linkeage (methods = "complete", "max", "mean"....)(gerarchico clustering)(divisivo e aglomerativo).
2) Genera diversi valori di "taglio" nel caso gerarchico, che andranno a creare diversi cluster (taglio = distanza da qui tagliare)

Colonne da non considerare durante l'analisi dei trend:
 9   participant_age1           146705 non-null  Int64         
 10  participant_age_group1     196755 non-null  string  
 25  notes                      157899 non-null  string        
 26  incident_characteristics1  238032 non-null  string        
 27  incident_characteristics2  141137 non-null  string 

3) controlla if max age = min age nel caso di n_participants = 1. 
4) controlla che i partecipanti (n_participants,n_females.... non siano tutte a null altrimenti eliminare.)

'date' ok per ora, 'state' ok, 
'city_or_county', no valori nulli ma manca il rimaneggiamento di "città (county)" e "città (nome frazione)" -> ok per ora, county si potrebbe rimuovere
'latitude','longitude', ok 

'congressional_district', 'state_house_district', 'state_senate_district' ok

'povertyPercentage', 'party', 'candidatevotes', 'totalvotes' ok

'address', 'notes', 'year' -> attributi da eliminare ok


Da fare: 
'n_participants_child', 'n_participants_teen', 'n_participants_adult', ok

'n_males', 'n_females', 'n_killed', 'n_injured','n_arrested', 'n_unharmed', 'n_participants', ok 
 
- matrice di correlazione e giustificarla.
'participant_age1', 'min_age_participants', 'avg_age_participants', 'max_age_participants' -> ok, possiamo mantenere participant_age1 per usare anche 'participant_age_group1' e
       'participant_gender1',

POST 26:
'incident_characteristics1', 'incident_characteristics2', manca il filling o da verificare se ha senso 

#TODO: improve the mean checking nmale + nfemale = nparticipant
#TODO: aggiungi  crimine rispetto alla somma dei crimini in quello stato e distretto e in base al partito politico

crimine rispetto alla percentuale di povertà e partito politico

teen nel crimine rispetto alla somma dei teen in quello stato

lo stesso con adult

lo stesso con child

lo stesso con male e female


-clustering: 
- fare vedere che c'è una clustering structure (con pca)
- scaling dei dati ok
- k means: selection k con elbow e caratterizzazione
- DBSCAN: selection stato su cui fare il clustering, selection su eps, minpts (elbow) e caratterizzazione
- HIERARCHICAL: " , selection parametri, ", caratterizzazione
- x-means stesso di k-means

todo: """ df_2018 = df[df['date'].dt.year == 2018]
df = df[~(df['date'].dt.year == 2018)]  """

todo classificazione: df['involve_killing'] = np.where(df['n_killed'] > 0, 1, 0)

add some entropy meausre in dp: from scipy.stats import entropy
df['avg_age_participants_entropy'] = df['avg_age_participants'].transform(entropy)
df['avg_age_participants_entropy'].fillna(0)


indicatori troppo correlati:

killed,injured,arrested,unharmed (1/somma e media) con stato / distretto (1/somma)
adult con males